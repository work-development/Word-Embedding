# Word Embedding   

<p align="justify">
Будем работать с англоязычным датасетом, составленным из рецептов 
</p>

## Модель     

* word2vec (SkipGram)     
* Softmax (с аппроксимацией Negative Sampling)

<p align="justify">
Моделируем условное распределение соседних слов в некотором окне при условии того, что мы пронаблюдали центральное слово. Разложим распределение на произведения более простых распределений - насколько вероятно можно встретить какое-то контекстное слово рядом с центральным словом (обучение word2vec сводится к обучению классификатора, который предсказывает — могут ли два слова встретиться в рамках какого-то небольшого окна, или не могут). В этом распределении есть две категориальные случайные величины.  Моделировать эти категориальные распределения будим с помощью Softmax в который подаём оценки сходства слов. Для оптимизации Softmax заменим сумму по всему словарю в знаменателе суммой по небольшому количеству случайно выбранных слов и, каждый раз, когда нам нужно посчитать аппроксимацию к софтмаксу, будим выбирать новые случайные слова (negative sampling). Сходство слов мы будем моделировать как скалярное произведение векторов этих слов. В моделе SkipGram для каждого слова у нас есть два вектора — первый вектор используется, когда слово находится в центре скользящего окна, и второй вектор используется, когда это слово описывает контекст (т.о. есть две матрицы проинициализированные равномерным шумом). Настраивать значения этих матриц будим методом бинарной кросс-энтропии. 
</p>

##  Универсальные компоненты     

* Токенизация   
* Построение словаря   
* pytorch Dataset    
* Паддинги
* Бинарная кросс-энтропия

## Основные функции и классы   


<b>PaddedSequenceDataset</b> - класс c 2-мя методами:   
    1-ый метод определяет сколько предложений в нём есть;   
    2-ой метод возвращения предложение по номеру, так что если предложение короче некоторой заданной длины, то он добавляет нули в конец этого предложения, если предложение длиннее установленного порога, то он его обрезает. Эта функция возвращает пары — а именно "текст" и "какая-то метка", которую по этому тексту нужно предсказывать (если задача классификации).




## Технологии
* [PyTorch](https://pytorch.org/)   
* [pandas](https://pandas.pydata.org/)
* [numpy](https://numpy.org/)
* [matplotlib](https://matplotlib.org/)
